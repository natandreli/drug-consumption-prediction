# Clasificaci贸n del Consumo de Drogas Basado en Rasgos de Personalidad y Datos Demogr谩ficos

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Status](https://img.shields.io/badge/Status-Completed-green)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Focus](https://img.shields.io/badge/Focus-Machine%20Learning%20%7C%20Psychometrics-red)

> **Predicci贸n de riesgo multi-salida basada en el modelo de los "Cinco Grandes" (Big Five) utilizando el dataset de la UCI.**

## Descripci贸n del Proyecto

Este proyecto aborda el desaf铆o de predecir el nivel de consumo de **6 sustancias psicoactivas** (Cannabis, Coca铆na, Hero铆na, xtasis, Benzodiacepinas y LSD) bas谩ndose exclusivamente en perfiles psicol贸gicos y datos demogr谩ficos.

A diferencia de enfoques binarios tradicionales, este modelo implementa una **Regresi贸n Multi-Salida (Multi-Output)** para predecir un 铆ndice de riesgo en una escala ordinal de 7 niveles (0-6), permitiendo una granularidad mucho mayor en la estratificaci贸n del riesgo.

### Fuente de Datos
El conjunto de datos utilizado es el **Drug Consumption (Quantified)** del Repositorio de Machine Learning de la UCI: **[Enlace al Dataset Oficial](https://archive.ics.uci.edu/dataset/373/drug+consumption+quantified)**

### Objetivos Principales
1. **Modelado Predictivo:** Comparar el desempe帽o de modelos lineales, ensambles y redes neuronales en un problema de alta dimensionalidad y desbalance de clases.
2. **Reducci贸n de Dimensi贸n:** Evaluar si el cuestionario psicom茅trico puede simplificarse mediante PCA o UMAP sin perder capacidad predictiva.
3. **Interpretabilidad:** Identificar qu茅 rasgos de personalidad (ej. *Sensation Seeking*) son los detonantes principales del consumo.

## Tecnolog铆as y Herramientas

El proyecto fue desarrollado en Python utilizando las siguientes librer铆as:

* **Procesamiento de Datos:** `pandas`, `numpy`, `imbalanced-learn` (RandomOverSampler).
* **Machine Learning:** `scikit-learn` (Ridge, KNN, RF, SVR, PCA), `umap-learn`.
* **Deep Learning:** `torch` (PyTorch) para la Red Neuronal Multi-Task.
* **Optimizaci贸n:** `optuna` para la b煤squeda bayesiana de hiperpar谩metros.
* **Visualizaci贸n:** `matplotlib`, `seaborn`, `plotly`.

## Metodolog铆a

### 1. Preprocesamiento
* **Limpieza:** Transformaci贸n de variables categ贸ricas y codificaci贸n ordinal.
* **Balanceo:** Aplicaci贸n de **Random OverSampling (ROS)** para mitigar el desbalance severo en clases minoritarias (usuarios de hero铆na/LSD).
* **Escalado:** Estandarizaci贸n de rasgos num茅ricos (StandardScaler).

### 2. Modelos Evaluados
Se entrenaron y optimizaron 5 familias de algoritmos:
* **Ridge Regression:** Baseline lineal con regularizaci贸n L2.
* **K-Nearest Neighbors (KNN):** Regresi贸n no param茅trica basada en instancias.
* **Multi-Task Neural Network:** MLP con *backbone* compartido y cabezas espec铆ficas por droga.
* **Random Forest Regressor:** Ensamble de 谩rboles (Bagging).
* **Support Vector Regression (SVR):** Modelado con kernel RBF.

### 3. Reducci贸n de Dimensi贸n
Se analiz贸 la redundancia de las 33 variables de entrada comparando **PCA** (lineal) vs **UMAP** (manifold learning).

## Resultados Clave

| Modelo | RMSE Global | RMSLE | Conclusi贸n |
| :--- | :---: | :---: | :--- |
| **Random Forest** | **1.48** | **0.620** |  **Mejor Desempe帽o.** Robusto a ruido y no-linealidades. |
| Red Neuronal | 1.51 | 0.667 | Competitivo, pero requiere m谩s datos para generalizar. |
| SVR | 1.62 | 0.669 | Dificultad para modelar la granularidad fina (7 clases). |
| Ridge (Base) | 1.77 | 0.787 | Insuficiente para capturar la complejidad del problema. |

### Hallazgos Importantes
* **Sensation Seeking & Openness:** Son los predictores m谩s potentes, superando a cualquier variable demogr谩fica.
* **Eficacia de PCA:** Se logr贸 reducir el espacio de entrada de **33 a 11 variables** (66% de reducci贸n) manteniendo el error del Random Forest estable (RMSLE 0.626). Esto sugiere que los tests psicol贸gicos pueden acortarse significativamente en producci贸n.
* **Falla de UMAP:** Las proyecciones de UMAP degradaron el rendimiento de regresi贸n (+22% de error), demostrando que la preservaci贸n de estructura local no favorece la predicci贸n de magnitudes globales.
